# ğŸ“ RAG_Solutions

This directory contains my practical work on Retrieval-Augmented Generation (RAG) systems, covering the full journey from fundamentals and experimentation (notebooks) to production-style Python implementations and evaluation.

The project follows a progressive learning path, moving from basic RAG concepts to modular, reusable, and evaluatable RAG pipelines.

## ğŸ“‚ Project Structure

```
RAG_Solutions/
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ eval.py            # RAG evaluation logic
â”‚   â”œâ”€â”€ test.py            # Test cases for RAG outputs
â”‚   â””â”€â”€ tests.jsonl        # Golden test dataset
â”‚
â”œâ”€â”€ knowledge-base/        # Source documents used for RAG
â”‚
â”œâ”€â”€ langchain_Solution/
â”‚   â”œâ”€â”€ part1.ipynb        # RAG fundamentals & simple pipelines
â”‚   â””â”€â”€ part2.ipynb        # Complete RAG pipeline with LangChain
â”‚
â”œâ”€â”€ preprocessed_db/       # Chunked & processed documents
â”‚
â”œâ”€â”€ pro_implementation/
â”‚   â”œâ”€â”€ ingest.py          # Data ingestion & vectorization
â”‚   â””â”€â”€ answer.py          # RAG query answering pipeline
â”‚
â”œâ”€â”€ vector_db/             # Vector database (Chroma / FAISS)
â”‚
â”œâ”€â”€ evaluator.py           # End-to-end RAG evaluation runner
â””â”€â”€ Rag_Solution.ipynb     # High-level RAG experimentation notebook
```

## ğŸ§  langchain_Solution/

This directory contains notebook-based implementations using LangChain to explore and understand RAG concepts.

**Covers:**
- Document loading and chunking
- Vector embeddings
- Vector stores
- Retriever + LLM integration
- End-to-end RAG pipelines

ğŸ“Œ *These notebooks focus on learning, experimentation, and debugging.*

## âš™ï¸ pro_implementation/

This directory contains a production-oriented RAG implementation written as Python scripts, not notebooks.

**Key characteristics:**
- Modular code structure
- Clear separation between ingestion and inference
- Designed to be reusable and extensible
- Closer to how RAG systems are built in real applications

ğŸ“Œ *This represents the transition from experimentation to production-ready RAG.*

## ğŸ“Š evaluation/

This directory is dedicated to evaluating RAG performance.

**Includes:**
- Golden datasets (`tests.jsonl`)
- Automated evaluation scripts
- Comparison of RAG outputs against expected answers

ğŸ“Œ *Evaluation is treated as a core component of the system.*

## ğŸ¯ Goals of This Project

- Understand RAG fundamentals and best practices
- Build complete RAG pipelines using LangChain
- Design modular, production-style RAG systems
- Evaluate retrieval and generation quality systematically

## ğŸ§© Technologies Used

- Python
- LangChain
- Vector Databases (Chroma / FAISS)
- OpenAI / Encoder Embedding Models
- JSONL evaluation datasets

---

**Note:** This project demonstrates the complete lifecycle of building RAG systemsâ€”from initial experimentation to production deployment and evaluation.
